{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_list = pd.read_csv('data/user_list_GH2.csv', index_col='Unnamed: 0')\n",
    "path = 'data/'\n",
    "train = pd.read_csv('{}train.csv'.format(path))\n",
    "test = pd.read_csv('{}test.csv'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쓸모없는 칼럼 삭제\n",
    "for df in (train,test):\n",
    "    df.drop(['FLAG_MOBIL'], axis=1, inplace=True)   \n",
    "    df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ID컬럼 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개인정보를 나열한 칼럼 ID 추가 (만약 여기서 credit도 추가하게 되면 고유 ID가 12099명으로 증가함)\n",
    "# 12099명으로 증가하는 경우는 유추하자면 credit 정보가 최신화되지 않았기 때문에 발생한다.\n",
    "# 따라서 가장 최근의 credit을 user_list로 반영하기 위한 작업을 실시한다.\n",
    "# 과거와 최근을 구별하는 방법은 bigin_month(카드 생성 후 기간)을 기준으로 시행한다.\n",
    "\n",
    "def ID_col(df_1, df_2):\n",
    "    \"\"\"[데이터 셋 전처리 함수입니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([Dataset]): [데이터셋을 입력해주세요]\n",
    "        df_2 ([Dataset]): [데이터셋을 입력해주세요]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "    \n",
    "    \n",
    "    for name, dataset, in zip(names, df_list):\n",
    "        dataset['ID'] = dataset['gender'].astype(str) + ' & ' + dataset['car'].astype(str) + ' & ' + dataset['reality'].astype(str) + ' & ' + \\\n",
    "                        dataset['child_num'].astype(str) + ' & ' + dataset['income_total'].astype(str) + ' & ' + dataset['income_type'].astype(str) + ' & ' + \\\n",
    "                        dataset['edu_type'].astype(str) + ' & ' + dataset['family_type'].astype(str) + ' & ' + dataset['house_type'].astype(str) + ' & ' + \\\n",
    "                        dataset['DAYS_BIRTH'].astype(str) + ' & ' + dataset['DAYS_EMPLOYED'].astype(str) + ' & ' + dataset['work_phone'].astype(str) + ' & ' + \\\n",
    "                        dataset['phone'].astype(str) + ' & ' + dataset['email'].astype(str)  + ' & ' + dataset['family_size'].astype(str)\n",
    "        # 최신 credit반영을 위한 정렬\n",
    "        dataset = dataset.sort_values(['begin_month', 'ID'], ascending=[False, True])\n",
    "        \n",
    "        # ID 중복되는 경우 True, 중복안된 고유값은 False로 설정하여 그 값의 개수를 확인한다\n",
    "        # ID_TF 칼럼을 형성하여 True, False를 반영해준다.\n",
    "        dataset['ID_TF'] = dataset.duplicated(['ID'])\n",
    "        dataset = dataset.reset_index(inplace=False)\n",
    "        print('해당 Data 내의 고유 ID 수는 {} 입니다.'.format(dataset['ID_TF'].value_counts()[0]))\n",
    "        \n",
    "        # card_num이라는 카드 개수를 추가하였음 (ID가 같은데 카드 개수가 여러 개인 사람을 대상으로 카드 개수를 구해서 데이터에 반영한다)\n",
    "        print('Column(card_num)을 생성합니다.')\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            a = dataset.iloc[i]['ID']\n",
    "            b = len(dataset[dataset['ID']==a])\n",
    "            dataset.loc[(dataset['ID']==a), 'card_num'] =  b\n",
    "\n",
    "        # 추출한 데이터프레임 (begin_month를 기준으로 최근의 credit을 반영)\n",
    "        print('최근의 credit을 반영합니다')\n",
    "        subset = dataset.query('ID_TF == False')\n",
    "        subset = subset.reset_index(inplace=False)\n",
    "        subset.drop(columns=['ID_TF'], inplace=True)\n",
    "        \n",
    "        # ID가 같은 사람을 뽑고 카드 보유기간의 평균을 뽑는다\n",
    "        print('dataset에서 평균값을 추출합니다')\n",
    "        for j in tqdm(range(len(dataset))):\n",
    "            c = dataset.iloc[j]['ID']\n",
    "            d = abs(int(dataset[dataset['ID']==c]['begin_month'].mean()))\n",
    "            subset.loc[(subset['ID']==c), 'begin_month_mean'] =  d\n",
    "        \n",
    "        \n",
    "        print('신규로 카드를 개설한 사람의 수 : {}'.format(len(dataset[dataset['begin_month']==0.0]['ID'].unique())))\n",
    "        print('카드를 신규 개설하고 그 카드가 첫번째인 사람의 수 : {}'.format(len(subset[subset['begin_month_mean']==0.0])))\n",
    "        print('dataset(user_list_{})을 저장합니다. \\n'.format(name))    \n",
    "        subset.to_csv('data/user_list_{}.csv'.format(name))\n",
    "        \n",
    "    del df_list, a, b, c, d, subset, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 Data 내의 고유 ID 수는 8759 입니다.\n",
      "Column(card_num)을 생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26457/26457 [03:41<00:00, 119.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근의 credit을 반영합니다\n",
      "dataset에서 평균값을 추출합니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26457/26457 [03:07<00:00, 141.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신규로 카드를 개설한 사람의 수 : 214\n",
      "카드를 신규 개설하고 그 카드가 첫번째인 사람의 수 : 29\n",
      "dataset(user_list_train)을 저장합니다.\n",
      "해당 Data 내의 고유 ID 수는 5585 입니다.\n",
      "Column(card_num)을 생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 231.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근의 credit을 반영합니다\n",
      "dataset에서 평균값을 추출합니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:39<00:00, 254.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신규로 카드를 개설한 사람의 수 : 82\n",
      "카드를 신규 개설하고 그 카드가 첫번째인 사람의 수 : 30\n",
      "dataset(user_list_test)을 저장합니다.\n"
     ]
    }
   ],
   "source": [
    "ID_col(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "\n",
    "user_list_train = pd.read_csv('{}user_list_train.csv'.format(path))\n",
    "user_list_test = pd.read_csv('{}user_list_test.csv'.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### faimly_size 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.\n",
      "family_size 7명 이상인 사람의 수 : 5\n",
      "family_size 7명 이상인 사람의 수 : 0\n",
      "1인당 소득으로 소득 수준을 조정합니다.\n",
      "train데이터 셋 처리 완료.\n",
      "\n",
      "family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.\n",
      "family_size 7명 이상인 사람의 수 : 4\n",
      "family_size 7명 이상인 사람의 수 : 0\n",
      "1인당 소득으로 소득 수준을 조정합니다.\n",
      "test데이터 셋 처리 완료.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_value_family(df_1, df_2, num_of_outlier):\n",
    "    \"\"\"[Family_size의 outlier를 대치해주는 작업을 시행합니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        num_of_outlier ([outlier_standard]): [family_size의 outlier 기준을 입력하세요]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    for dataset,name in zip(df_list,names):\n",
    "        print('family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.')\n",
    "        dataset.drop(columns=['child_num'], inplace=True)\n",
    "        print('family_size {}명 이상인 사람의 수 : {}'.format(num_of_outlier, \n",
    "                                                        len(dataset.loc[dataset['family_size'] >= num_of_outlier])))\n",
    "        sub = dataset.loc[dataset['family_size']>= num_of_outlier]\n",
    "        for i in range(len(sub)):\n",
    "            a = int(dataset[dataset['family_type'] == sub['family_type'].values[i]].mean()['family_size'])\n",
    "            dataset.loc[(dataset['family_size']>= num_of_outlier), 'family_size'] = a\n",
    "        \n",
    "        print('family_size {}명 이상인 사람의 수 : {}'.format(num_of_outlier, \n",
    "                                                        len(dataset.loc[dataset['family_size'] >= num_of_outlier])))        # # family_size가 6을 초과하는 사람을 다른 값으로 대치하는 작업\n",
    "\n",
    "        # family_size를 조정하고 난 후에 1인당 소득으로 total_income을 scale_down 해줌.\n",
    "        print('1인당 소득으로 소득 수준을 조정합니다.')\n",
    "        dataset['income_mean'] = dataset['income_total'] / dataset['family_size']\n",
    "        print('{}데이터 셋 처리 완료.\\n'.format(name))\n",
    "    \n",
    "    del sub,df_list, names\n",
    "        \n",
    "replace_value_family(user_list_train, user_list_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### card_num 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_num이 20 값 이상인 사람의 수 : 9\n",
      "card_num이 20 값 이상인 사람의 수 : 0\n",
      "train데이터 셋 처리 완료.\n",
      "\n",
      "card_num이 20 값 이상인 사람의 수 : 0\n",
      "card_num이 20 값 이상인 사람의 수 : 0\n",
      "test데이터 셋 처리 완료.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sns.boxenplot('card_num', data = user_list)\n",
    "# plt.show()\n",
    "# 카드 개수가 20개 이상인 사람을 대상으로 전처리 필요 판단\n",
    "\n",
    "# col_corr_list(user_list, 'card_num')\n",
    "# 해당 함수를 시행한 결과, card_num과 begin_month, credit의 상관성이 존재함을 확인\n",
    "\n",
    "def replace_value_add(df_1,df_2,feature_name, standard_feature_1,  num_of_outlier):\n",
    "    \"\"\"[outlier를 대치하는 함수입니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        feature_name ([column name]): [outlier처리가 필요한 컬럼 이름을 입력해주세요]\n",
    "        standard_feature_1 ([type]): [처리가 필요한 컬럼과 상관성이 높은 컬럼을 입력해주세요]\n",
    "        num_of_outlier ([type]): [outlier 기준을 입력해주세요]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    for dataset,name in zip(df_list,names):\n",
    "        print('{}이 {} 값 이상인 사람의 수 : {}'.format(feature_name ,num_of_outlier, \n",
    "                                                   len(dataset.loc[dataset[feature_name] >= num_of_outlier])))\n",
    "        sub = dataset.loc[dataset[feature_name]>= num_of_outlier]\n",
    "        for i in range(len(sub)):\n",
    "            a = int(dataset[dataset[standard_feature_1] == sub[standard_feature_1].values[i]].mean()[feature_name])\n",
    "            dataset.loc[(dataset[feature_name]>=num_of_outlier), feature_name] = a\n",
    "        \n",
    "        print('{}이 {} 값 이상인 사람의 수 : {}'.format(feature_name ,num_of_outlier, \n",
    "                                                   len(dataset.loc[dataset[feature_name] >= num_of_outlier])))   \n",
    "        print('{}데이터 셋 처리 완료.\\n'.format(name))\n",
    "\n",
    "    del df_list, sub, a, names\n",
    "    \n",
    "replace_value_add(user_list_train, user_list_test, 'card_num', 'begin_month', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나이, 고용연수 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_month_total(df_1, df_2, column, column_name):\n",
    "    \"\"\"[나이, 고용연수 파생변수를 생성하기 위한 함수입니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        column ([생성할 컬럼의 기준 컬럼 명]): [생성할 컬럼의 기준 컬럼 명을 입력해주세요]\n",
    "        column_name ([생성할 컬럼의 이름]): [연단위, 연+월단위로 표시된 파생변수 이름입니다.]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    if (column == 'DAYS_BIRTH') == True:    \n",
    "        for dataset,name in zip(df_list,names):\n",
    "            dataset['{}_year'.format(column_name)] = dataset[column].abs()//365\n",
    "            dataset['{}_month'.format(column_name)] = (dataset[column].abs()%365)//30\n",
    "            dataset['{}_total'.format(column_name)] = dataset['{}_year'.format(column_name)] + round(dataset['{}_month'.format(column_name)] * (1/12), 2)\n",
    "            dataset.drop(columns=['{}_month'.format(column_name)], inplace=True)\n",
    "        \n",
    "            print('{}set에 {}_year, {}_total 컬럼을 생성하였습니다. \\n'.format(name,column_name,column_name))\n",
    "    \n",
    "    else:\n",
    "        for dataset,name in zip(df_list,names):\n",
    "            print('{}set에 근무일자가 잘못기입된 {} cases에 대한 처리를 시작합니다.'.format(name, len(dataset[dataset['DAYS_EMPLOYED']>=0])))\n",
    "            dataset['DAYS_EMPLOYED'].sort_values().value_counts()\n",
    "            dataset['DAYS_EMPLOYED'] = dataset['DAYS_EMPLOYED'].replace(365243, 0)\n",
    "            dataset.query('DAYS_EMPLOYED < 0')['DAYS_EMPLOYED'].sort_values()\n",
    "\n",
    "            dataset['{}_year'.format(column_name)] = dataset[column].abs()//365\n",
    "            dataset['{}_month'.format(column_name)] = (dataset[column].abs()%365)//30\n",
    "            dataset['{}_total'.format(column_name)] = dataset['{}_year'.format(column_name)] + round(dataset['{}_month'.format(column_name)] * (1/12), 2)\n",
    "            dataset.drop(columns=['{}_month'.format(column_name)], inplace=True)\n",
    "        \n",
    "            print('{}set에 {}_year, {}_total 컬럼을 생성하였습니다. \\n'.format(name, column_name,column_name))\n",
    "        \n",
    "    del df_list,names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset에 age_year, age_total 컬럼을 생성하였습니다. \n",
      "\n",
      "testset에 age_year, age_total 컬럼을 생성하였습니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_month_total(user_list_train, user_list_test,'DAYS_BIRTH','age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset에 근무일자가 잘못기입된 1508 cases에 대한 처리를 시작합니다.\n",
      "trainset에 work_year, work_total 컬럼을 생성하였습니다. \n",
      "\n",
      "testset에 근무일자가 잘못기입된 973 cases에 대한 처리를 시작합니다.\n",
      "testset에 work_year, work_total 컬럼을 생성하였습니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_month_total(user_list_train, user_list_test,'DAYS_EMPLOYED','work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 근무일자는 근무연수로 표시한 경우 & 근무연수,개월,통합으로 정확한 값으로 표시한 경우 두가지로 진행해볼 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 근무일자를 제대로 표시하기 위한 작업\n",
    "# print('근무일자가 잘못기입된 숫자 : {}'.format(len(user_list[user_list['DAYS_EMPLOYED']>=0])))\n",
    "\n",
    "# #워킹일자 0보다 큰 값은 무효값으로 양수 전부 0으로 처리 후 work_year 칼럼 생성 (여기서는 work_year를 반올림한 값으로 처리)\n",
    "# user_list['DAYS_EMPLOYED'].sort_values().value_counts()\n",
    "# user_list['DAYS_EMPLOYED'] = user_list['DAYS_EMPLOYED'].replace(365243, 0)\n",
    "# user_list.query('DAYS_EMPLOYED < 0')['DAYS_EMPLOYED'].sort_values()\n",
    "# user_list['work_year'] = user_list['DAYS_EMPLOYED'].abs()/365\n",
    "# user_list['work_year'] = user_list['work_year'].round()\n",
    "# # user_list['work_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### occpy_type Nan 값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직업 컬럼의 Nan value 중 1508 명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.\n",
      "나머지 값은 no_data로 처리합니다.\n",
      "trainset의 직업 Nan value를 처리하였습니다.\n",
      "\n",
      "직업 컬럼의 Nan value 중 973 명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.\n",
      "나머지 값은 no_data로 처리합니다.\n",
      "testset의 직업 Nan value를 처리하였습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def occyp_type_nan(df_1, df_2):\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    for dataset,name in zip(df_list,names):\n",
    "        dataset['occyp_type'] = dataset['occyp_type'].fillna('Nan')\n",
    "        print('직업 컬럼의 Nan value 중 {} 명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.'.format(len(dataset.loc[(dataset['occyp_type'] == 'Nan') & (dataset['DAYS_EMPLOYED'] == 0)])))\n",
    "        dataset.loc[(dataset['occyp_type'] == 'Nan') & (dataset['DAYS_EMPLOYED'] == 0), 'occyp_type'] = 'jobless'\n",
    "        print('나머지 값은 no_data로 처리합니다.')\n",
    "        dataset.loc[dataset['occyp_type'] == 'Nan', 'occyp_type'] = 'no data'\n",
    "        print('{}set의 직업 Nan value를 처리하였습니다.\\n'.format(name))\n",
    "        \n",
    "    del df_list, names\n",
    "\n",
    "occyp_type_nan(user_list_train, user_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['train', 'test']\n",
    "\n",
    "for name,dataset in zip(names, [user_list_train, user_list_test]):\n",
    "    dataset.drop(columns=['DAYS_BIRTH','DAYS_EMPLOYED','level_0','index'], inplace=True)\n",
    "    dataset.to_csv('data/final_set_{}.csv'.format(name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e194ca94d9d720df57297bf37581ae4a889736a9f9aea5aedd380eb1a7083ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pythonProject4': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
