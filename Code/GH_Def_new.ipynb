{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "train = pd.read_csv('{}train.csv'.format(path))\n",
    "test = pd.read_csv('{}test.csv'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쓸모없는 칼럼 삭제\n",
    "for df in (train,test):\n",
    "    df.drop(['FLAG_MOBIL'], axis=1, inplace=True)   \n",
    "    df.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st\n",
    "\n",
    "def year_month_total(df_1, df_2, column, column_name):\n",
    "    \"\"\"[나이, 고용연수 파생변수를 생성하기 위한 함수입니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        column ([생성할 컬럼의 기준 컬럼 명]): [생성할 컬럼의 기준 컬럼 명을 입력해주세요]\n",
    "        column_name ([생성할 컬럼의 이름]): [연단위, 연+월단위로 표시된 파생변수 이름입니다.]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    if (column == 'DAYS_BIRTH') == True:    \n",
    "        for dataset,name in zip(df_list,names):\n",
    "            dataset['{}_year'.format(column_name)] = dataset[column].abs()//365\n",
    "            dataset['{}_month'.format(column_name)] = (dataset[column].abs()%365)//30\n",
    "            dataset['{}_total'.format(column_name)] = dataset['{}_year'.format(column_name)] + round(dataset['{}_month'.format(column_name)] * (1/12), 2)\n",
    "            dataset.drop(columns=['{}_month'.format(column_name)], inplace=True)\n",
    "        \n",
    "            print('{}set에 {}_year, {}_total 컬럼을 생성하였습니다. \\n'.format(name,column_name,column_name))\n",
    "    \n",
    "    else:\n",
    "        for dataset,name in zip(df_list,names):\n",
    "            print('{}set에 근무일자가 잘못기입된 {} cases에 대한 처리를 시작합니다.'.format(name, len(dataset[dataset['DAYS_EMPLOYED']>=0])))\n",
    "            dataset['DAYS_EMPLOYED'].sort_values().value_counts()\n",
    "            dataset['DAYS_EMPLOYED'] = dataset['DAYS_EMPLOYED'].replace(365243, 0)\n",
    "            dataset.query('DAYS_EMPLOYED < 0')['DAYS_EMPLOYED'].sort_values()\n",
    "\n",
    "            dataset['{}_year'.format(column_name)] = dataset[column].abs()//365\n",
    "            dataset['{}_month'.format(column_name)] = (dataset[column].abs()%365)//30\n",
    "            dataset['{}_total'.format(column_name)] = dataset['{}_year'.format(column_name)] + round(dataset['{}_month'.format(column_name)] * (1/12), 2)\n",
    "            dataset.drop(columns=['{}_month'.format(column_name)], inplace=True)\n",
    "        \n",
    "            print('{}set에 {}_year, {}_total 컬럼을 생성하였습니다. \\n'.format(name, column_name,column_name))\n",
    "        \n",
    "    del df_list,names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset에 age_year, age_total 컬럼을 생성하였습니다. \n",
      "\n",
      "testset에 age_year, age_total 컬럼을 생성하였습니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_month_total(train, test,'DAYS_BIRTH','age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset에 근무일자가 잘못기입된 4438 cases에 대한 처리를 시작합니다.\n",
      "trainset에 work_year, work_total 컬럼을 생성하였습니다. \n",
      "\n",
      "testset에 근무일자가 잘못기입된 1697 cases에 대한 처리를 시작합니다.\n",
      "testset에 work_year, work_total 컬럼을 생성하였습니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_month_total(train, test,'DAYS_EMPLOYED','work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직업 컬럼의 Nan value 8171명 중 4438명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.\n",
      "나머지 3733명 데이터는 no_data로 처리합니다.\n",
      "trainset의 직업 Nan value를 처리하였습니다.\n",
      "\n",
      "직업 컬럼의 Nan value 3152명 중 1697명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.\n",
      "나머지 1455명 데이터는 no_data로 처리합니다.\n",
      "testset의 직업 Nan value를 처리하였습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd\n",
    "\n",
    "def occyp_type_nan(df_1, df_2):\n",
    "    \"\"\"[직업 컬럼 내의 Nan 값을 처리합니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    for dataset,name in zip(df_list,names):\n",
    "        dataset['occyp_type'] = dataset['occyp_type'].fillna('Nan')\n",
    "        print('직업 컬럼의 Nan value {}명 중 {}명이 실제 고용일수가 0일입니다. 따라서 jobless로 처리합니다.'.format(len(dataset.loc[dataset['occyp_type'] == 'Nan']), len(dataset.loc[(dataset['occyp_type'] == 'Nan') & (dataset['DAYS_EMPLOYED'] == 0)])))\n",
    "        dataset.loc[(dataset['occyp_type'] == 'Nan') & (dataset['DAYS_EMPLOYED'] == 0), 'occyp_type'] = 'jobless'\n",
    "        print('나머지 {}명 데이터는 no_data로 처리합니다.'.format(len(dataset.loc[dataset['occyp_type'] == 'Nan'])))\n",
    "        dataset.loc[dataset['occyp_type'] == 'Nan', 'occyp_type'] = 'no data'\n",
    "        print('{}set의 직업 Nan value를 처리하였습니다.\\n'.format(name))\n",
    "        \n",
    "    del df_list, names\n",
    "\n",
    "occyp_type_nan(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ID컬럼 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개인정보를 나열한 칼럼 ID 추가 (만약 여기서 credit도 추가하게 되면 고유 ID가 12099명으로 증가함)\n",
    "# 12099명으로 증가하는 경우는 유추하자면 credit 정보가 최신화되지 않았기 때문에 발생한다.\n",
    "# 따라서 가장 최근의 credit을 user_list로 반영하기 위한 작업을 실시한다.\n",
    "# 과거와 최근을 구별하는 방법은 bigin_month(카드 생성 후 기간)을 기준으로 시행한다.\n",
    "\n",
    "\n",
    "def ID_col(df_1, df_2):\n",
    "    \"\"\"[데이터 셋 전처리 함수입니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([Dataset]): [train 데이터셋을 입력해주세요]\n",
    "        df_2 ([Dataset]): [test 데이터셋을 입력해주세요]\n",
    "    \"\"\"\n",
    "        \n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    a = []\n",
    "    change_credit = 0\n",
    "    names = ['train', 'test']\n",
    "    \n",
    "    \n",
    "    for name, dataset, in zip(names, df_list):\n",
    "        dataset['ID'] = dataset['gender'].astype(str) +'.'+ dataset['car'].astype(str)+'.' + dataset['reality'].astype(str)+'.' + \\\n",
    "                dataset['child_num'].astype(str)+'.' + dataset['income_total'].astype(str) +'.'+ dataset['income_type'].astype(str) +'.'+ \\\n",
    "                dataset['edu_type'].astype(str)+'.' + dataset['family_type'].astype(str)+'.' + dataset['house_type'].astype(str) +'.'+ \\\n",
    "                dataset['DAYS_BIRTH'].astype(str) +'.'+ dataset['DAYS_EMPLOYED'].astype(str) +'.'+ dataset['work_phone'].astype(str) +'.'+ \\\n",
    "                dataset['phone'].astype(str) +'.'+ dataset['email'].astype(str) +'.' + dataset['family_size'].astype(str)+'.' + dataset['occyp_type'].astype(str)\n",
    "        \n",
    "        dataset = dataset.sort_values(['ID','begin_month'], ascending=[True, False])\n",
    "        dataset.reset_index(inplace=True)\n",
    "        dataset.drop(columns={'index'}, inplace=True)\n",
    "\n",
    "        print('해당 Data 내의 고유 ID 수는 {} 입니다. OridonalEncoder를 이용힌 변환을 시작합니다.'.format(dataset['ID'].nunique()))\n",
    "        encode = OrdinalEncoder()\n",
    "        dataset[['ID']] = encode.fit_transform(dataset[['ID']])\n",
    "\n",
    "        # Nth_card 컬럼 추가 (ID가 같은데 카드 개수가 여러 개인 사람을 대상으로 몇 번째 카드를 만들었는지 생성해준다)\n",
    "        print('Column(Nth_card)을 생성합니다.')\n",
    "        for i in tqdm(range(dataset['ID'].nunique())):\n",
    "            Nth_card = len(dataset[dataset['ID']==i]) + 1\n",
    "            \n",
    "            while Nth_card > 0:\n",
    "                Nth_card = Nth_card -1\n",
    "                a.append(Nth_card)\n",
    "                if Nth_card == 1:\n",
    "                    break\n",
    "                \n",
    "        dataset['Nth_card'] = a        \n",
    "        a.clear()\n",
    "        print('신규로 카드를 개설한 사람의 수 : {}'.format(len(dataset[dataset['begin_month']==0.0]['ID'].unique())))\n",
    "        \n",
    "        \n",
    "        if (dataset['ID'].nunique() > 8000)==True:\n",
    "            print('credit 정보를 확인하고 시간이 지나며 credit이 악화된 사례가 있는지 확인합니다.')\n",
    "            for i in tqdm(range(dataset['ID'].nunique())):\n",
    "                num = dataset.loc[dataset['ID'] == i]['credit'].to_list()\n",
    "                for j in range(len(num)-1):\n",
    "                    if (num[j] <= num[j+1]) == True:\n",
    "                        pass\n",
    "                    else :\n",
    "                        change_credit += 1\n",
    "                        break\n",
    "            print('{}명(전체 중 {:.2f}%)은 credit이 개선되지 않고 악화된 사례가 존재합니다.'.format(change_credit, \n",
    "                                                                        (change_credit/dataset['ID'].nunique())*100))  \n",
    "        else:\n",
    "            print('credit 정보가 없는 testset입니다.')\n",
    "            \n",
    "        print('dataset(user_list_{})을 저장합니다. \\n'.format(name))    \n",
    "        dataset.to_csv('{}user_list_{}.csv'.format(path, name))\n",
    "        \n",
    "    del names, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 Data 내의 고유 ID 수는 8759 입니다. OridonalEncoder를 이용힌 변환을 시작합니다.\n",
      "Column(Nth_card)을 생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8759/8759 [00:05<00:00, 1698.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신규로 카드를 개설한 사람의 수 : 214\n",
      "credit 정보를 확인하고 시간이 지나며 credit이 악화된 사례가 있는지 확인합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8759/8759 [00:07<00:00, 1196.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842명(전체 중 21.03%)은 credit이 개선되지 않고 악화된 사례가 존재합니다.\n",
      "dataset(user_list_train)을 저장합니다. \n",
      "\n",
      "해당 Data 내의 고유 ID 수는 5585 입니다. OridonalEncoder를 이용힌 변환을 시작합니다.\n",
      "Column(Nth_card)을 생성합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5585/5585 [00:04<00:00, 1312.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신규로 카드를 개설한 사람의 수 : 82\n",
      "credit 정보가 없는 testset입니다.\n",
      "dataset(user_list_test)을 저장합니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ID_col(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('{}user_list_train.csv'.format(path))\n",
    "test = pd.read_csv('{}user_list_test.csv'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8759/8759 [00:05<00:00, 1593.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842명(전체 중 21.03%)은 credit이 개선되지 않고 악화된 사례가 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "change_credit = 0\n",
    "\n",
    "for i in tqdm(range(dataset['ID'].nunique())):\n",
    "    num = dataset.loc[dataset['ID'] == i]['credit'].to_list()\n",
    "    for j in range(len(num)-1):\n",
    "        if (num[j] <= num[j+1]) == True:\n",
    "            pass\n",
    "        else :\n",
    "            change_credit += 1\n",
    "            break\n",
    "    \n",
    "print('{}명(전체 중 {:.2f}%)은 credit이 개선되지 않고 악화된 사례가 존재합니다.'.format(change_credit, \n",
    "                                                                      (change_credit/dataset['ID'].nunique())*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### faimly_size 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.\n",
      "family_size 7명 이상인 사람의 수 : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:41<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family_size 7명 이상인 사람의 수 : 0\n",
      "1인당 소득으로 소득 수준을 조정합니다.\n",
      "train데이터 셋 처리 완료.\n",
      "\n",
      "family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.\n",
      "family_size 7명 이상인 사람의 수 : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family_size 7명 이상인 사람의 수 : 0\n",
      "1인당 소득으로 소득 수준을 조정합니다.\n",
      "test데이터 셋 처리 완료.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_value_family(df_1, df_2, num_of_outlier):\n",
    "    \"\"\"[Family_size의 outlier를 대치해주는 작업을 시행합니다.]\n",
    "\n",
    "    Args:\n",
    "        df_1 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        df_2 ([DataFrame]): [데이터 프레임 이름을 입력해주세요]\n",
    "        num_of_outlier ([outlier_standard]): [family_size의 outlier 기준을 입력하세요]\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(df_1)\n",
    "    df_list.append(df_2)\n",
    "    names = ['train', 'test']\n",
    "\n",
    "    for dataset,name in zip(df_list,names):\n",
    "        print('family_size와 child_num의 다중공선성 문제로 child_num 컬럼을 삭제해줍니다.')\n",
    "        dataset.drop(columns=['child_num'], inplace=True)\n",
    "        print('family_size {}명 이상인 사람의 수 : {}'.format(num_of_outlier, \n",
    "                                                        len(dataset.loc[dataset['family_size'] >= num_of_outlier])))\n",
    "        sub = dataset.loc[dataset['family_size']>= num_of_outlier]\n",
    "        for i in tqdm(range(len(sub))):\n",
    "            a = int(dataset[dataset['family_type'] == sub['family_type'].values[i]].mean()['family_size'])\n",
    "            dataset.loc[(dataset['family_size']>= num_of_outlier), 'family_size'] = a\n",
    "        \n",
    "        print('family_size {}명 이상인 사람의 수 : {}'.format(num_of_outlier, \n",
    "                                                        len(dataset.loc[dataset['family_size'] >= num_of_outlier])))        # # family_size가 6을 초과하는 사람을 다른 값으로 대치하는 작업\n",
    "\n",
    "        # family_size를 조정하고 난 후에 1인당 소득으로 total_income을 scale_down 해줌.\n",
    "        print('1인당 소득으로 소득 수준을 조정합니다.')\n",
    "        dataset['income_mean'] = dataset['income_total'] / dataset['family_size']\n",
    "        print('{}데이터 셋 처리 완료.\\n'.format(name))\n",
    "    \n",
    "    del sub,df_list, names\n",
    "        \n",
    "replace_value_family(train, test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['train', 'test']\n",
    "path = 'data/'\n",
    "\n",
    "for name,dataset in zip(names, [user_list_train, user_list_test]):\n",
    "    dataset.drop(columns=['DAYS_BIRTH','DAYS_EMPLOYED','level_0','index'], inplace=True)\n",
    "    dataset.to_csv('{}final_set_{}.csv'.format(path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e194ca94d9d720df57297bf37581ae4a889736a9f9aea5aedd380eb1a7083ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pythonProject4': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
